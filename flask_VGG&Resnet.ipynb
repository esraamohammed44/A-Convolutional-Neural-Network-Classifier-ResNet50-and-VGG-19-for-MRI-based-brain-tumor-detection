{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c04a5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to C:\\Users\\Electronica Care/.cache\\torch\\hub\\checkpoints\\vgg19-dcbb9e9d.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 548M/548M [07:00<00:00, 1.37MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TF\n",
    "from torchvision.transforms import ToTensor, Grayscale\n",
    "\n",
    "# Load VGG19 model\n",
    "vgg19 = models.vgg19(pretrained=True)\n",
    "\n",
    "# Modify VGG19 to accept 1-channel input\n",
    "vgg19.features[0] = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "# Freeze VGG19 parameters\n",
    "for param in vgg19.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "#Resnet Architecture\n",
    "\n",
    "def conv3x3(in_planes,out_planes,stride=1):\n",
    "    return nn.Conv2d(in_planes,out_planes,kernel_size=3,stride=stride,padding=1,bias=False)\n",
    "\n",
    "def conv1x1(in_planes,out_planes,stride=1):\n",
    "    return nn.Conv2d(in_planes,out_planes,kernel_size=1,stride=stride,bias=False)\n",
    "\n",
    "# Load ResNet model\n",
    "# Define the ResNet block and layer functions\n",
    "# ...\n",
    "\n",
    "# Define the ResNet model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define the basic block for ResNet\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "# Define the ResNet model\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=2):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Usage example:\n",
    "resnet = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=2)\n",
    "\n",
    "\n",
    "# Combine the models\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, vgg_model, resnet_model):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.vgg = vgg_model\n",
    "        self.resnet = resnet_model\n",
    "        self.fc = nn.Linear(1000 + 2, 2)  # Assuming the last layer has 1000 units in VGG19\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convert RGB images to grayscale\n",
    "        x = Grayscale()(x)\n",
    "        if not isinstance(x, torch.Tensor):\n",
    "            x = TF.to_tensor(x)\n",
    "        vgg_features = self.vgg(x)\n",
    "        resnet_features = self.resnet(x)\n",
    "        features = torch.cat((vgg_features, resnet_features), dim=1)\n",
    "        output = self.fc(features)\n",
    "        return output\n",
    "\n",
    "# Create the combined model\n",
    "combined_model = CombinedModel(vgg19, resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34f27cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the combined model\n",
    "combined_model = CombinedModel(vgg19, resnet)\n",
    "\n",
    "combined_model.load_state_dict(torch.load(\"300epoch_VGG.pth\",map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2ec6a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
